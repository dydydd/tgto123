import requests
import os
import logging
from bs4 import BeautifulSoup
import time
import sqlite3
logger = logging.getLogger(__name__)
from datetime import datetime
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from p115client.p115client.client import P115Client, check_response, normalize_attr as normalize_attr_simple
from p115client.p115client.exception import P115OSError, AuthenticationError
from urllib.parse import urlsplit, parse_qs
import re
import schedule
banbenhao = "1.0.7"

from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv(dotenv_path="db/user.env",override=True)
load_dotenv(dotenv_path="sys.env",override=True)
# é…ç½®éƒ¨åˆ†
# å®‰å…¨åœ°è·å–æ•´æ•°å€¼ï¼Œé¿å…å¼‚å¸¸
def get_int_env(env_name, default_value=0):
    try:
        value = os.getenv(env_name, str(default_value))
        return int(value) if value else default_value
    except (ValueError, TypeError):
        TelegramNotifier(os.getenv("ENV_TG_BOT_TOKEN", ""), int(os.getenv("ENV_TG_ADMIN_USER_ID", "0"))).send_message(f"[è­¦å‘Š] ç¯å¢ƒå˜é‡ {env_name} å€¼ä¸æ˜¯æœ‰æ•ˆçš„æ•´æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼ {default_value}")
        logger.warning(f"ç¯å¢ƒå˜é‡ {env_name} å€¼ä¸æ˜¯æœ‰æ•ˆçš„æ•´æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼ {default_value}")
        return default_value

CHANNEL_URL = os.getenv("ENV_115_TG_CHANNEL", "")
COOKIES = os.getenv("ENV_115_COOKIES",
                    "")
UPLOAD_TARGET_PID = get_int_env("ENV_UPLOAD_PID", 0)
UPLOAD_TRANSFER_PID = get_int_env("ENV_115_UPLOAD_PID", 0)

TG_BOT_TOKEN = os.getenv("ENV_TG_BOT_TOKEN", "")
TG_ADMIN_USER_ID = get_int_env("ENV_TG_ADMIN_USER_ID", 0)

# æ¸…ç†ä»»åŠ¡é…ç½®å‚æ•°
CLEAN_TARGET_PID = os.getenv("ENV_115_CLEAN_PID", "0,0")  # é»˜è®¤ç©ºå­—ç¬¦ä¸²
TRASH_PASSWORD = get_int_env("ENV_115_TRASH_PASSWORD", 0)

# ä¿®æ”¹æ•°æ®åº“æ–‡ä»¶è·¯å¾„åˆ° db ç›®å½•ä¸‹
DB_DIR = "db"
if not os.path.exists(DB_DIR):
    os.makedirs(DB_DIR)
DATABASE_FILE = os.path.join(DB_DIR, "TG_monitor-115.db")
CHECK_INTERVAL = get_int_env("ENV_CHECK_INTERVAL", 5)  # æ£€æŸ¥é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.5 Safari/605.1.15"
]
RETRY_TIMES = 3
TIMEOUT = 15

# å…¨å±€115å®¢æˆ·ç«¯ï¼ˆé¿å…é‡å¤åˆå§‹åŒ–ï¼‰
client_115 = None

# ç²¾ç®€å…¨å±€è®¡æ•°å™¨
stats = {
    "total_files": 0
}

def init_115_client():
    """åˆå§‹åŒ–115å®¢æˆ·ç«¯ï¼ˆcookiesè®¤è¯ï¼‰"""
    global client_115
    if not client_115:
        try:
            client_115 = P115Client(cookies=COOKIES)
            # éªŒè¯å®¢æˆ·ç«¯æ˜¯å¦æœ‰æ•ˆ
            client_115.user_info()
            #print("[115å®¢æˆ·ç«¯] åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"115å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
            TelegramNotifier(TG_BOT_TOKEN, TG_ADMIN_USER_ID).send_message(f"[115å®¢æˆ·ç«¯] åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
            raise
    return client_115

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼ˆå¢åŠ è½¬å­˜çŠ¶æ€å­—æ®µï¼‰"""
    conn = sqlite3.connect(DATABASE_FILE)
    conn.execute('''CREATE TABLE IF NOT EXISTS messages
                 (msg_id INTEGER PRIMARY KEY AUTOINCREMENT, id TEXT, date TEXT, message_url TEXT, target_url TEXT, 
                   transfer_status TEXT, transfer_time TEXT, transfer_result TEXT)''')
    conn.commit()
    conn.close()

def is_message_processed(message_url):
    """æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å·²å¤„ç†ï¼ˆæ— è®ºè½¬å­˜æ˜¯å¦æˆåŠŸï¼‰"""
    conn = sqlite3.connect(DATABASE_FILE)
    result = conn.execute("SELECT 1 FROM messages WHERE message_url = ?",
                          (message_url,)).fetchone()
    conn.close()
    return result is not None

def save_message(message_id, date, message_url, target_url,
                 status="å¾…è½¬å­˜", result="", transfer_time=None):
    """ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“ï¼ŒåŒ…å«è½¬å­˜çŠ¶æ€"""
    conn = sqlite3.connect(DATABASE_FILE)
    try:
        conn.execute("INSERT INTO messages (id, date, message_url, target_url, transfer_status, transfer_time, transfer_result) VALUES (?, ?, ?, ?, ?, ?, ?)",
                     (message_id, date, message_url, target_url,
                      status, transfer_time or datetime.now().isoformat(), result))
        conn.commit()
        logger.info(f"å·²è®°å½•: {message_id} | {target_url} | çŠ¶æ€: {status}")
    except sqlite3.IntegrityError:
        # æ›´æ–°å·²æœ‰è®°å½•çš„çŠ¶æ€
        conn.execute("UPDATE messages SET transfer_status=?, transfer_result=?, transfer_time=? WHERE id=?",
                     (status, result, transfer_time or datetime.now().isoformat(), message_id))
        conn.commit()
    finally:
        conn.close()

def get_latest_messages():
    """è·å–æœ€æ–°æ¶ˆæ¯ï¼ˆä»æœ€åä¸€æ¡å¼€å§‹æ£€æŸ¥ï¼‰"""
    try:
        # è·å–å¤šä¸ªé¢‘é“é“¾æ¥
        channel_urls = os.getenv("ENV_115_TG_CHANNEL", "").split('|')
        if not channel_urls or channel_urls == ['']:
            logger.warning("æœªé…ç½®ENV_115_TG_CHANNELç¯å¢ƒå˜é‡")
            return []
            
        all_new_messages = []
        
        for channel_idx, channel_url in enumerate(channel_urls):
            channel_url = channel_url.strip()
            if not channel_url:
                continue

            if channel_url.startswith('https://t.me/') and '/s/' not in channel_url:
                # æå–é¢‘é“åç§°éƒ¨åˆ†
                channel_name = channel_url.split('https://t.me/')[-1]
                # é‡æ„URLï¼Œæ·»åŠ /s/
                channel_url = f'https://t.me/s/{channel_name}'

            logger.info(f"===== å¤„ç†ç¬¬{channel_idx + 1}ä¸ªé¢‘é“: {channel_url} =====")
            
            session = requests.Session()
            retry = Retry(total=RETRY_TIMES, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
            session.mount("https://", HTTPAdapter(max_retries=retry))
            headers = {"User-Agent": USER_AGENTS[int(time.time()) % len(USER_AGENTS)]}
            response = session.get(channel_url, headers=headers, timeout=TIMEOUT)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')

            message_divs = soup.find_all('div', class_='tgme_widget_message')
            total = len(message_divs)
            logger.info(f"å…±è§£æåˆ°{total}æ¡æ¶ˆæ¯ï¼ˆæœ€æ–°çš„åœ¨æœ€åï¼‰")

            new_messages = []

            for i in range(total):
                msg_index = total - 1 - i  # ä»æœ€åä¸€æ¡ï¼ˆæœ€æ–°ï¼‰å¼€å§‹
                msg = message_divs[msg_index]
                data_post = msg.get('data-post', '')
                message_id = data_post.split('/')[-1] if data_post else f"æœªçŸ¥ID_{msg_index}"
                logger.info(f"æ£€æŸ¥ç¬¬{i + 1}æ–°æ¶ˆæ¯ï¼ˆå€’æ•°ç¬¬{i + 1}æ¡ï¼ŒID: {message_id}ï¼‰")

                time_elem = msg.find('time')
                date_str = time_elem.get('datetime') if time_elem else datetime.now().isoformat()
                link_elem = msg.find('a', class_='tgme_widget_message_date')
                message_url = f"{link_elem.get('href').lstrip('/')}" if link_elem else ''
                text_elem = msg.find('div', class_='tgme_widget_message_text')

                if text_elem:
                    # æå–æ¶ˆæ¯æ–‡æœ¬å†…å®¹ï¼ˆæ¸…ç†ç©ºæ ¼å’Œæ¢è¡Œï¼‰
                    message_text = text_elem.get_text(strip=True).replace('\n', ' ')
                    target_urls = extract_target_url(f"{msg}")
                    if target_urls:
                        for url in target_urls:
                            if not is_message_processed(message_url):
                                new_messages.append((message_id, date_str, message_url, url, message_text))
                                logger.info(message_url)
                            else:
                                logger.info(f"ç¬¬{i + 1}æ–°æ¶ˆæ¯å·²å¤„ç†ï¼Œè·³è¿‡")
                                logger.info(f"tgæ¶ˆæ¯é“¾æ¥ï¼š{message_url}")
                                logger.info(f"115é“¾æ¥ï¼š{url}")
                    else:
                        logger.info("æœªå‘ç°ç›®æ ‡115é“¾æ¥")
            
            all_new_messages.extend(new_messages)
        
        # æŒ‰æ—¶é—´æ­£åºæ’åˆ—æ‰€æœ‰æ¶ˆæ¯
        all_new_messages.sort(key=lambda x: x[1])
        logger.info(f"===== æ‰€æœ‰é¢‘é“å¤„ç†å®Œæˆï¼Œå…±å‘ç°{len(all_new_messages)}æ¡æ–°çš„115åˆ†äº«é“¾æ¥ =====")
        return all_new_messages

    except requests.exceptions.RequestException as e:
        logger.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)[:100]}")
        return []

def extract_target_url(text):
    import re
    pattern = r'https?:\/\/(?:115|115cdn|anxia)\.com\/s\/\w+\?password\=\w+'
    matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
    if matches:
        # å»é™¤é‡å¤é“¾æ¥
        unique_matches = list(set([match.strip() for match in matches]))
        return unique_matches
    return []

class Fake115Client(object):
    def __init__(self, cookies, cliHelper: P115Client):
        self.cookies = cookies
        self.ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'
        self.content_type = 'application/x-www-form-urlencoded'
        self.header = {"User-Agent": self.ua,
                       "Content-Type": self.content_type, "Cookie": self.cookies}
        self.get_userid()
        self.cliHelper = cliHelper

    # è·å–UID
    def get_userid(self):
        try:
            self.user_id = ''
            url = "https://my.115.com/?ct=ajax&ac=get_user_aq"
            p = requests.get(url, headers=self.header)
            if p:
                rootobject = p.json()
                if not rootobject.get("state"):
                    self.err = "[x] è·å– UID é”™è¯¯ï¼š{}".format(rootobject.get("error_msg"))
                    return False
                self.user_id = rootobject.get("data").get("uid")
                return True
        except Exception as result:
            logger.error(f"å¼‚å¸¸é”™è¯¯ï¼š{result}")
        return False

    def request_datalist(self, share_code, receive_code):
        url = f"https://webapi.115.com/share/snap?share_code={share_code}&offset=0&limit=20&receive_code={receive_code}&cid="
        data_list = []
        share_info = {}
        try:
            response = requests.get(url, headers=self.header)
            response_json = response.json()
            share_info = response_json['data'].get('shareinfo')
            if response_json['state'] == False:
                logger.error(f"error: {response_json['error']}")
                return share_info, []
            count = response_json['data']['count']
            data_list.extend(response_json['data']['list'])
            while len(data_list) < count:
                offset = len(data_list)
                response = requests.get(f"{url}&offset={offset}")
                response_json = response.json()
                data_list.extend(response_json['data']['list'])
        except:
            data_list = []
        return share_info, data_list

    def post_save(self, share_code, receive_code, file_ids, pid='', req_delay=2):
        time.sleep(req_delay)
        file_id_str = ','.join(file_ids)
        if pid == '':
            payload = {
                'user_id': self.user_id,
                'share_code': share_code,
                'receive_code': receive_code,
                'file_id': file_id_str
            }
        else:
            payload = {
                'user_id': self.user_id,
                'share_code': share_code,
                'receive_code': receive_code,
                'file_id': file_id_str,
                'cid': pid
            }
        try:
            response = requests.post('https://webapi.115.com/share/receive', data=payload, headers=self.header)
        except Exception as e:
            logger.error(f"è½¬å­˜å¤±è´¥: {str(e)}")
            notifier = TelegramNotifier(TG_BOT_TOKEN, TG_ADMIN_USER_ID)
            notifier.send_message(f"è½¬å­˜å¤±è´¥: {str(e)}")
            return False
        result = response.json()
        if not result['state']:
            error_msg = result.get("error", "")
            logger.error(f'è½¬å­˜ {share_code}:{receive_code} å¤±è´¥ï¼ŒåŸå› ï¼š{error_msg}')
            # å½“é”™è¯¯ä¿¡æ¯ä¸º"æ–‡ä»¶å·²æ¥æ”¶ï¼Œæ— éœ€é‡å¤æ¥æ”¶ï¼"æ—¶ï¼Œè§†ä¸ºè½¬å­˜æˆåŠŸ
            if "æ— éœ€é‡å¤æ¥æ”¶" in error_msg:
                response.close()
                return True
            TelegramNotifier(TG_BOT_TOKEN, TG_ADMIN_USER_ID).send_message(f"115è½¬å­˜å¤±è´¥ï¼Œå¤±è´¥åŸå› ï¼š{error_msg}")
        response.close()
        return result['state']

    def share_link_parser(self, link) -> tuple:
        match = re.search(r'https?:\/\/(115|115cdn|anxia)\.com\/s\/(\w+)\?password\=(\w+)', link, re.IGNORECASE | re.DOTALL)
        if not match:
            logger.error(f'é“¾æ¥æ ¼å¼é”™è¯¯, link={link}')
            TelegramNotifier(TG_BOT_TOKEN, TG_ADMIN_USER_ID).send_message(f'é“¾æ¥æ ¼å¼é”™è¯¯, link={link}')
            return None
        share_code = match.group(2)
        receive_code = match.group(3)
        return (share_code, receive_code)

    def save_link(self, share_item, pid="") -> bool:
        share_code = share_item[0]
        receive_code = share_item[1]
        share_info, data_list = self.request_datalist(share_code, receive_code)
        file_ids = []
        for data in data_list:
            cid = data.get('fid', data['cid'])
            file_ids.append(cid)
        if self.post_save(share_code=share_code, receive_code=receive_code, file_ids=file_ids, pid=pid):
            return True
        return False

def transfer_shared_link(client: P115Client, share_url: str, target_pid: int):
    """
    è½¬å­˜ 115 åˆ†äº«é“¾æ¥åˆ°æŒ‡å®šç›®å½•
    :param client: P115Client å®ä¾‹
    :param share_url: 115 åˆ†äº«é“¾æ¥ï¼ˆå«æå–ç ï¼‰
    :param target_pid: ç›®æ ‡ç›®å½• PID
    """
    try:       
        fake_client = Fake115Client(cookies=COOKIES, cliHelper=client)
        share_item = fake_client.share_link_parser(share_url)
        if share_item:
            return fake_client.save_link(share_item, str(target_pid))

    except Exception as e:
        logger.error(f"è½¬å­˜å¤±è´¥: {str(e)}")
        notifier = TelegramNotifier(TG_BOT_TOKEN, TG_ADMIN_USER_ID)
        notifier.send_message(f"è½¬å­˜å¤±è´¥: {str(e)}")
        return False

def print_progress(msg, indent=0):
    """å¸¦ç¼©è¿›çš„è¿›åº¦è¾“å‡º"""
    prefix = "  " * indent
    logger.info(f"{prefix}[{time.strftime('%H:%M:%S')}] {msg}")

def transfer_and_clean():
    """é€’å½’è½¬ç§»æ–‡ä»¶å¹¶æ¸…ç†ç©ºç›®å½•ï¼ˆå¸¦è¯¦ç»†æ—¥å¿—ï¼‰"""
    global stats
    client = P115Client(cookies=COOKIES)

    def recursive_transfer(current_pid: int, depth=0):
        # è·å–å½“å‰ç›®å½•åç§°
        try:
            dir_info = client.fs_get_info(current_pid)
            dir_name = dir_info.get("name", f"ç›®å½•#{current_pid}")
        except:
            dir_name = f"ç›®å½•#{current_pid}"
        print_progress(f"æ‰«æç›®å½•: {dir_name} ({current_pid})", depth)

        # è·å–å½“å‰ç›®å½•å†…å®¹ï¼ˆå¸¦åˆ†é¡µå¤„ç†ï¼‰
        items = []
        offset = 0
        while True:
            try:
                resp = client.fs_files_app({
                    "cid": current_pid,
                    "limit": 1000,
                    "offset": offset
                })
                check_response(resp)
                page_items = resp["data"]
                items.extend(page_items)

                if len(page_items) < 1000:
                    break  # æ²¡æœ‰æ›´å¤šæ•°æ®
                offset += 1000
                print_progress(f"  è¯»å–åˆ†é¡µ: {offset / 1000 + 1}", depth + 1)
            except Exception as e:
                print_progress(f"âš ï¸ è·å–ç›®å½•å†…å®¹å¤±è´¥: {str(e)}", depth + 1)
                break

        print_progress(f"å‘ç° {len(items)} ä¸ªé¡¹ç›®", depth + 1)

        # åˆ†ç¦»æ–‡ä»¶å’Œç›®å½•ï¼ˆå…ˆå¤„ç†æ–‡ä»¶ï¼‰
        files = [item for item in items if not normalize_attr_simple(item)["is_dir"]]
        dirs = [item for item in items if normalize_attr_simple(item)["is_dir"]]

        # è½¬ç§»æ‰€æœ‰æ–‡ä»¶
        for i, file in enumerate(files, 1):
            normalized = normalize_attr_simple(file)
            file_name = normalized.get("name", f"æ–‡ä»¶#{normalized['id']}")
            progress = f"{i}/{len(files)}"
            try:
                move_resp = client.fs_move_app(
                    {"ids": normalized["id"], "to_cid": UPLOAD_TARGET_PID},
                    app="android"
                )
                check_response(move_resp)
                print_progress(f"âœ… ç§»åŠ¨æ–‡ä»¶: {file_name} ({progress})", depth + 1)
                stats["total_files"] += 1
            except Exception as e:
                print_progress(f"âŒ ç§»åŠ¨å¤±è´¥: {file_name} ({progress}) - {str(e)}", depth + 1)
            time.sleep(0.2)  # æ¯ä¸ªæ–‡ä»¶è½¬ç§»åä¼‘çœ  0.2 ç§’

        # é€’å½’å¤„ç†å­ç›®å½•
        for directory in dirs:
            dir_id = normalize_attr_simple(directory)["id"]
            if dir_id == UPLOAD_TARGET_PID:
                print_progress(f"â© è·³è¿‡ç›®æ ‡ç›®å½•: {dir_id}", depth + 1)
                continue
            recursive_transfer(dir_id, depth + 1)

        # æ¸…ç†ç©ºç›®å½•
        try:
            after_resp = client.fs_files_app(current_pid)
            check_response(after_resp)
            if (not after_resp["data"]
                    and current_pid != UPLOAD_TARGET_PID
                    and current_pid != UPLOAD_TRANSFER_PID):
                del_resp = client.fs_delete_app(current_pid)
                check_response(del_resp)
                print_progress(f"ğŸ—‘ï¸ åˆ é™¤ç©ºç›®å½•: {dir_name} ({current_pid})", depth)
                time.sleep(1)  # æ¯ä¸ªç›®å½•æ¸…ç†åä¼‘çœ  1 ç§’
        except Exception as e:
            print_progress(f"âš ï¸ åˆ é™¤ç›®å½•å¤±è´¥: {dir_name} ({current_pid}) - {str(e)}", depth)

    # æ‰§è¡Œå‰æ£€æŸ¥
    if UPLOAD_TRANSFER_PID == 0:
        raise ValueError("è½¬ç§»ç›®å½•IDä¸èƒ½ä¸º0")

    logger.info("===== å¼€å§‹æ–‡ä»¶è½¬ç§»å’Œç›®å½•æ¸…ç† =====")
    logger.info(f"æºç›®å½•: {UPLOAD_TRANSFER_PID}")
    logger.info(f"ç›®æ ‡ç›®å½•: {UPLOAD_TARGET_PID}")
    logger.info("==================================\n")

    # æ‰§è¡Œè½¬ç§»
    try:
        recursive_transfer(UPLOAD_TRANSFER_PID)
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    finally:
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info("===== æ“ä½œå®Œæˆ =====")
        logger.info(f"ç¨‹åºè‡ªå¯åŠ¨åå…±è½¬å­˜æ–‡ä»¶æ•°: {stats['total_files']}")
        logger.info("===================\n")


def clean_task():
    """æ‰§è¡Œæ¸…ç†ä»»åŠ¡ï¼šä»…å½“ç›®æ ‡æ–‡ä»¶å¤¹IDå­˜åœ¨æ—¶æ‰æ‰§è¡Œæ“ä½œ"""
    # è§£æç›®æ ‡æ–‡ä»¶å¤¹IDï¼ˆè¿‡æ»¤ç©ºå€¼ï¼‰
    target_pids = [
        pid.strip()
        for pid in CLEAN_TARGET_PID.split(",")
        if pid.strip()
    ]

    # å¦‚æœç›®æ ‡æ–‡ä»¶å¤¹IDä¸ºç©ºï¼Œç›´æ¥é€€å‡º
    if not target_pids:
        logger.warning("æœªé…ç½®æœ‰æ•ˆç›®æ ‡æ–‡ä»¶å¤¹IDï¼Œä¸æ‰§è¡Œæ¸…ç†æ“ä½œ")
        return

    # åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨å…¨å±€é…ç½®çš„COOKIESï¼‰
    client = P115Client(cookies=COOKIES)

    try:
        # æ¸…ç†æ¯ä¸ªç›®æ ‡æ–‡ä»¶å¤¹å†…çš„å†…å®¹
        for cid in target_pids:
            logger.info(f"å¼€å§‹æ¸…ç†æ–‡ä»¶å¤¹ {cid} å†…çš„å†…å®¹...")
            offset = 0
            limit = 100  # åˆ†é¡µå¤§å°

            while True:
                # è·å–æ–‡ä»¶å¤¹å†…å®¹
                try:
                    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨fs_files_appå¯èƒ½æ¯”fs_filesæ›´ç¨³å®šï¼ˆå‚è€ƒtransfer_and_cleanä¸­çš„ç”¨æ³•ï¼‰
                    resp = client.fs_files_app({
                        "cid": cid,
                        "limit": limit,
                        "offset": offset,
                        "show_dir": 1
                    })
                    check_response(resp)
                    contents = resp.get("data", [])

                    if not contents:
                        logger.info(f"æ–‡ä»¶å¤¹ {cid} å†…æ— å†…å®¹ï¼Œæ¸…ç†å®Œæˆ")
                        break

                    # éå†åˆ é™¤å†…å®¹
                    for item in contents:
                        # å…³é”®ä¿®å¤ï¼šä½¿ç”¨normalize_attr_simpleè§„èŒƒåŒ–å±æ€§ï¼ˆåŸä»£ç ä¸­å·²æœ‰è¯¥å·¥å…·å‡½æ•°ï¼‰
                        normalized_item = normalize_attr_simple(item)
                        item_id = normalized_item.get("id")
                        item_name = normalized_item.get("name", "æœªçŸ¥åç§°")
                        is_dir = normalized_item.get("is_dir", False)

                        # æ–°å¢æ ¡éªŒï¼šè·³è¿‡æ— IDçš„æ— æ•ˆé¡¹ç›®
                        if not item_id:
                            logger.warning(f"è·³è¿‡æ— æ•ˆé¡¹ç›®ï¼ˆæ— IDï¼‰ï¼š{item_name}")
                            continue

                        try:
                            logger.info(f"åˆ é™¤{'ç›®å½•' if is_dir else 'æ–‡ä»¶'}: {item_name} (ID: {item_id})")
                            # æ³¨æ„ï¼šæ ¹æ®åŸä»£ç é£æ ¼ï¼Œä½¿ç”¨fs_delete_appæ›´å…¼å®¹
                            client.fs_delete_app(item_id)
                            time.sleep(0.5)  # å¢åŠ å°å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                        except Exception as e:
                            logger.error(f"åˆ é™¤ {item_name} å¤±è´¥: {str(e)}")

                    # å¤„ç†åˆ†é¡µ
                    if len(contents) < limit:
                        logger.info(f"æ–‡ä»¶å¤¹ {cid} å†…å®¹å·²å…¨éƒ¨æ¸…ç†")
                        break
                    offset += limit

                except Exception as e:
                    logger.error(f"è·å–æ–‡ä»¶å¤¹ {cid} å†…å®¹å¤±è´¥: {str(e)}")
                    break

        # æ¸…ç©ºå›æ”¶ç«™
        logger.info("å¼€å§‹æ¸…ç©ºå›æ”¶ç«™...")
        client.recyclebin_clean(password=TRASH_PASSWORD)
        logger.info("å›æ”¶ç«™æ¸…ç©ºå®Œæˆ")

    finally:
        client.close()

class TelegramNotifier:
    def __init__(self, bot_token, user_id):
        self.bot_token = bot_token
        self.user_id = user_id
        self.base_url = f"https://api.telegram.org/bot{self.bot_token}/" if self.bot_token else None

    def send_message(self, message):
        """å‘æŒ‡å®šç”¨æˆ·å‘é€æ¶ˆæ¯ï¼Œè‹¥bot_tokenæœªè®¾ç½®åˆ™è·³è¿‡å‘é€ï¼Œå¤±è´¥è‡ªåŠ¨é‡è¯•"""
        # å±€éƒ¨å˜é‡å®šä¹‰é‡è¯•å‚æ•°
        max_retries = 30  # é‡è¯•æ¬¡æ•°
        retry_delay = 60  # é‡è¯•é—´éš”

        # æ£€æŸ¥bot_tokenæ˜¯å¦å­˜åœ¨
        if not self.bot_token:
            logger.error("æœªè®¾ç½®bot_tokenï¼Œè·³è¿‡å‘é€æ¶ˆæ¯")
            return False
        if not message:
            logger.error("è­¦å‘Šï¼šæ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º")
            return False
        success_count = 0
        fail_count = 0
        params = {
            "chat_id": self.user_id,
            "text": message
        }

        for attempt in range(max_retries):
            try:
                response = requests.get(
                    f"{self.base_url}sendMessage",
                    params=params,
                    timeout=15  # ä½¿ç”¨å…¨å±€è¶…æ—¶é…ç½®
                )
                response.raise_for_status()
                result = response.json()
                if result.get("ok", False):
                    logger.info(f"æ¶ˆæ¯ '{message.replace('\n', '').replace('\r', '')[:20]}...' ï¼Œå·²æˆåŠŸå‘é€ç»™ç”¨æˆ· {TG_ADMIN_USER_ID}ï¼ˆç¬¬{attempt+1}/{max_retries}æ¬¡å°è¯•ï¼‰")
                    success_count += 1
                    break  # æˆåŠŸåˆ™ç»ˆæ­¢é‡è¯•
                else:
                    error_msg = result.get('description', 'æœªçŸ¥é”™è¯¯')
                    logger.error(f"å‘é€å›å¤å¤±è´¥ï¼Œ{retry_delay}ç§’åé‡å‘ï¼Œæ¶ˆæ¯ï¼š{message}ï¼Œé”™è¯¯ï¼š{error_msg}")
                    fail_count += 1
            except requests.exceptions.RequestException as e:
                logger.error(f"å‘é€å›å¤å¤±è´¥ï¼Œ{retry_delay}ç§’åé‡å‘ï¼Œæ¶ˆæ¯ï¼š{message}ï¼Œé”™è¯¯ï¼š{str(e)}")
                fail_count += 1

            # éæœ€åä¸€æ¬¡å°è¯•åˆ™ç­‰å¾…é‡è¯•
            if attempt < max_retries - 1:
                time.sleep(retry_delay)

        #logger.info(f"æ¶ˆæ¯å‘é€å®Œæˆ - æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}")
        return success_count > 0  # ä¿æŒåŸæœ‰è¿”å›å€¼é€»è¾‘

def tg_115monitor():
    init_database()
    client = init_115_client()
    notifier = TelegramNotifier(TG_BOT_TOKEN, TG_ADMIN_USER_ID)
    logger.info(f"===== å¼€å§‹æ£€æŸ¥ 115ï¼ˆ{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}ï¼‰=====")
    new_messages = get_latest_messages()
    #schedule.run_pending()
    if new_messages:
        for msg in new_messages:
            message_id, date_str, message_url, target_url, message_text = msg
            logger.info(f"å¤„ç†æ–°æ¶ˆæ¯: {message_id} | {target_url}")

            # è½¬å­˜åˆ°115
            result = transfer_shared_link(client, target_url, UPLOAD_TRANSFER_PID)
            if result:
                status = "è½¬å­˜æˆåŠŸ"
                result_msg = f"âœ…115ç½‘ç›˜è½¬å­˜æˆåŠŸ\næ¶ˆæ¯å†…å®¹: {message_url}\né“¾æ¥: {target_url}"
            else:
                status = "è½¬å­˜å¤±è´¥"
                result_msg = f"âŒ115ç½‘ç›˜è½¬å­˜å¤±è´¥\næ¶ˆæ¯å†…å®¹: {message_url}\né“¾æ¥: {target_url}"

            notifier.send_message(result_msg)

            # ä¿å­˜ç»“æœåˆ°æ•°æ®åº“
            save_message(message_id, date_str, message_url, target_url, status, result_msg)
    else:
        logger.info("æœªå‘ç°æ–°çš„115åˆ†äº«é“¾æ¥")

def main():
    try:       
        while True:
            tg_115monitor()
            time.sleep(CHECK_INTERVAL * 60)

    except KeyboardInterrupt:
        logger.info("ç¨‹åºå·²åœæ­¢")
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸ç»ˆæ­¢: {str(e)}")

if __name__ == "__main__":
    main()